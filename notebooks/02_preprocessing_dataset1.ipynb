{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09f462b",
   "metadata": {},
   "source": [
    "# Text Preprocessing - Dataset 1\n",
    "\n",
    "**Objective:** Prepare the multi-labeled toxic comments dataset for BERT training\n",
    "\n",
    "**Tasks:**\n",
    "1. Load and clean Bengali text data\n",
    "2. Handle Bengali-specific preprocessing needs\n",
    "3. Prepare data for tokenization\n",
    "4. Create train/validation/test splits\n",
    "5. Basic text analysis for BERT compatibility\n",
    "\n",
    "**Dataset:** Multi-labeled toxic comments (16,073 samples)\n",
    "**Labels:** vulgar, hate, religious, threat, troll, Insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36cd82d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bengali text preprocessing...\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "# Text processing\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Starting Bengali text preprocessing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4682784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (16073, 7)\n",
      "Columns: ['text', 'vulgar', 'hate', 'religious', 'threat', 'troll', 'Insult']\n",
      "\n",
      "Text column sample:\n",
      "['প্রধানমন্ত্রী হক সাহেবের ক্ষতি হলে জাতির স্বার্থে কেনো কোনো বাম পক্ষ কে ছাড় দেয়ার উচিত না', 'আমি বললাম, ‘দেন’', 'অসাধারণ তানজিন তিশা আমার বালো লাগার একজনকাতার থেকে']\n",
      "\n",
      "Label columns: ['vulgar', 'hate', 'religious', 'threat', 'troll', 'Insult']\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset 1\n",
    "df = pd.read_csv('../data/Multi_labeled_toxic_comments.csv')\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Quick verification\n",
    "print(f\"\\nText column sample:\")\n",
    "print(df['text'].head(3).tolist())\n",
    "\n",
    "# Label columns\n",
    "label_columns = ['vulgar', 'hate', 'religious', 'threat', 'troll', 'Insult']\n",
    "print(f\"\\nLabel columns: {label_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ec5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Analysis for BERT Compatibility\n",
      "========================================\n",
      "Text length statistics:\n",
      "  Mean: 80.0 characters\n",
      "  Median: 59.0 characters\n",
      "  Max: 1402 characters\n",
      "  95th percentile: 205.0 characters\n",
      "\n",
      "Word count statistics:\n",
      "  Mean: 14.2 words\n",
      "  Median: 11.0 words\n",
      "  Max: 238 words\n",
      "\n",
      "Texts with less than 5 characters: 25\n",
      "Texts with more than 500 characters: 49\n"
     ]
    }
   ],
   "source": [
    "# Analyze text characteristics for BERT preprocessing\n",
    "print(\"Text Analysis for BERT Compatibility\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Basic text statistics\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['word_count'] = df['text'].str.split().str.len()\n",
    "\n",
    "print(f\"Text length statistics:\")\n",
    "print(f\"  Mean: {df['text_length'].mean():.1f} characters\")\n",
    "print(f\"  Median: {df['text_length'].median():.1f} characters\")\n",
    "print(f\"  Max: {df['text_length'].max()} characters\")\n",
    "print(f\"  95th percentile: {df['text_length'].quantile(0.95):.1f} characters\")\n",
    "\n",
    "print(f\"\\nWord count statistics:\")\n",
    "print(f\"  Mean: {df['word_count'].mean():.1f} words\")\n",
    "print(f\"  Median: {df['word_count'].median():.1f} words\")\n",
    "print(f\"  Max: {df['word_count'].max()} words\")\n",
    "\n",
    "# Check for very short texts\n",
    "short_texts = (df['text_length'] < 5).sum()\n",
    "print(f\"\\nTexts with less than 5 characters: {short_texts}\")\n",
    "\n",
    "# Check for very long texts (BERT has 512 token limit)\n",
    "long_texts = (df['text_length'] > 500).sum()\n",
    "print(f\"Texts with more than 500 characters: {long_texts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba055de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing text cleaning function:\n",
      "Original: আমি খুব খুশি!!!\n",
      "Cleaned:  আমি খুব খুশি!\n",
      "\n",
      "Original: এটা কি???   অনেক স্পেস   \n",
      "Cleaned:  এটা কি? অনেক স্পেস\n",
      "\n",
      "Original: http://example.com এই লিংক দেখো\n",
      "Cleaned:  এই লিংক দেখো\n",
      "\n",
      "Original: test@email.com এই ইমেইল\n",
      "Cleaned:  এই ইমেইল\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_bengali_text(text):\n",
    "    \"\"\"\n",
    "    Clean Bengali text for BERT preprocessing\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Remove URLs (common in social media)\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove excessive punctuation (keep single instances)\n",
    "    text = re.sub(r'[!]{2,}', '!', text)\n",
    "    text = re.sub(r'[?]{2,}', '?', text)\n",
    "    text = re.sub(r'[.]{3,}', '...', text)\n",
    "    \n",
    "    # Remove extra spaces again\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test the cleaning function\n",
    "print(\"Testing text cleaning function:\")\n",
    "test_texts = [\n",
    "    \"আমি খুব খুশি!!!\",\n",
    "    \"এটা কি???   অনেক স্পেস   \",\n",
    "    \"http://example.com এই লিংক দেখো\",\n",
    "    \"test@email.com এই ইমেইল\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    cleaned = clean_bengali_text(text)\n",
    "    print(f\"Original: {text}\")\n",
    "    print(f\"Cleaned:  {cleaned}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ffe295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying text cleaning to dataset...\n",
      "Cleaning comparison examples:\n",
      "\n",
      "Example 1:\n",
      "Original: প্রধানমন্ত্রী হক সাহেবের ক্ষতি হলে জাতির স্বার্থে কেনো কোনো বাম পক্ষ কে ছাড় দেয়ার উচিত না\n",
      "Cleaned:  প্রধানমন্ত্রী হক সাহেবের ক্ষতি হলে জাতির স্বার্থে কেনো কোনো বাম পক্ষ কে ছাড় দেয়ার উচিত না\n",
      "\n",
      "Example 2:\n",
      "Original: আমি বললাম, ‘দেন’\n",
      "Cleaned:  আমি বললাম, ‘দেন’\n",
      "\n",
      "Example 3:\n",
      "Original: অসাধারণ তানজিন তিশা আমার বালো লাগার একজনকাতার থেকে\n",
      "Cleaned:  অসাধারণ তানজিন তিশা আমার বালো লাগার একজনকাতার থেকে\n",
      "\n",
      "Texts that became empty after cleaning: 0\n",
      "\n",
      "Cleaned text length statistics:\n",
      "  Mean: 79.8 characters\n",
      "  Median: 59.0 characters\n",
      "  Max: 1395 characters\n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning to the dataset\n",
    "print(\"Applying text cleaning to dataset...\")\n",
    "\n",
    "# Create a copy for safety\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Apply cleaning function\n",
    "df_clean['text_cleaned'] = df_clean['text'].apply(clean_bengali_text)\n",
    "\n",
    "# Compare before and after\n",
    "print(\"Cleaning comparison examples:\")\n",
    "for i in range(3):\n",
    "    original = df['text'].iloc[i]\n",
    "    cleaned = df_clean['text_cleaned'].iloc[i]\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Cleaned:  {cleaned}\")\n",
    "\n",
    "# Check if any texts became empty after cleaning\n",
    "empty_after_cleaning = (df_clean['text_cleaned'].str.len() == 0).sum()\n",
    "print(f\"\\nTexts that became empty after cleaning: {empty_after_cleaning}\")\n",
    "\n",
    "# Update length statistics\n",
    "df_clean['cleaned_length'] = df_clean['text_cleaned'].str.len()\n",
    "print(f\"\\nCleaned text length statistics:\")\n",
    "print(f\"  Mean: {df_clean['cleaned_length'].mean():.1f} characters\")\n",
    "print(f\"  Median: {df_clean['cleaned_length'].median():.1f} characters\")\n",
    "print(f\"  Max: {df_clean['cleaned_length'].max()} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5821681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling problematic texts...\n",
      "Texts shorter than 3 characters: 5\n",
      "Examples of short texts:\n",
      "      text text_cleaned  cleaned_length\n",
      "857     মর           মর               2\n",
      "3466    হু           হু               2\n",
      "8898    --           --               2\n",
      "9816    --           --               2\n",
      "14385    -            -               1\n",
      "Dataset size after removing short texts: 16068\n"
     ]
    }
   ],
   "source": [
    "# Handle problematic texts\n",
    "print(\"Handling problematic texts...\")\n",
    "\n",
    "# Find texts that are too short after cleaning\n",
    "min_length = 3  # Minimum meaningful text length\n",
    "short_mask = df_clean['cleaned_length'] < min_length\n",
    "\n",
    "print(f\"Texts shorter than {min_length} characters: {short_mask.sum()}\")\n",
    "\n",
    "if short_mask.sum() > 0:\n",
    "    print(\"Examples of short texts:\")\n",
    "    short_examples = df_clean[short_mask][['text', 'text_cleaned', 'cleaned_length']].head()\n",
    "    print(short_examples)\n",
    "    \n",
    "    # Decision: Remove very short texts or keep original\n",
    "    # For this project, we'll remove texts shorter than 3 characters\n",
    "    df_clean = df_clean[~short_mask].copy()\n",
    "    \n",
    "    print(f\"Dataset size after removing short texts: {len(df_clean)}\")\n",
    "else:\n",
    "    print(\"No problematic short texts found.\")\n",
    "\n",
    "# Reset index\n",
    "df_clean = df_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3157752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution Analysis\n",
      "==============================\n",
      "vulgar: 2,505 samples (15.6%)\n",
      "hate: 1,898 samples (11.8%)\n",
      "religious: 1,418 samples (8.8%)\n",
      "threat: 1,418 samples (8.8%)\n",
      "troll: 1,643 samples (10.2%)\n",
      "Insult: 2,719 samples (16.9%)\n",
      "\n",
      "Multi-label statistics:\n",
      "Samples with 0 labels: 7,581\n",
      "Samples with 1+ labels: 8,487\n",
      "Average labels per sample: 0.72\n",
      "\n",
      "Distribution of labels per sample:\n",
      "  0 labels: 7,581 samples\n",
      "  1 labels: 5,836 samples\n",
      "  2 labels: 2,209 samples\n",
      "  3 labels: 421 samples\n",
      "  4 labels: 21 samples\n"
     ]
    }
   ],
   "source": [
    "# Analyze label distribution in cleaned dataset\n",
    "print(\"Label Distribution Analysis\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "label_columns = ['vulgar', 'hate', 'religious', 'threat', 'troll', 'Insult']\n",
    "\n",
    "# Calculate label statistics\n",
    "label_stats = {}\n",
    "for label in label_columns:\n",
    "    count = df_clean[label].sum()\n",
    "    percentage = (count / len(df_clean)) * 100\n",
    "    label_stats[label] = {'count': count, 'percentage': percentage}\n",
    "    print(f\"{label}: {count:,} samples ({percentage:.1f}%)\")\n",
    "\n",
    "# Multi-label statistics\n",
    "df_clean['total_labels'] = df_clean[label_columns].sum(axis=1)\n",
    "print(f\"\\nMulti-label statistics:\")\n",
    "print(f\"Samples with 0 labels: {(df_clean['total_labels'] == 0).sum():,}\")\n",
    "print(f\"Samples with 1+ labels: {(df_clean['total_labels'] > 0).sum():,}\")\n",
    "print(f\"Average labels per sample: {df_clean['total_labels'].mean():.2f}\")\n",
    "\n",
    "# Show distribution of number of labels per sample\n",
    "label_distribution = df_clean['total_labels'].value_counts().sort_index()\n",
    "print(f\"\\nDistribution of labels per sample:\")\n",
    "for num_labels, count in label_distribution.items():\n",
    "    print(f\"  {num_labels} labels: {count:,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffb7b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/validation/test splits...\n",
      "Dataset splits:\n",
      "  Training set: 11,253 samples (70.0%)\n",
      "  Validation set: 2,404 samples (15.0%)\n",
      "  Test set: 2,411 samples (15.0%)\n",
      "\n",
      "Label distribution across splits:\n",
      "  vulgar: Train 15.6% | Val 16.1% | Test 15.3%\n",
      "  hate: Train 11.9% | Val 11.6% | Test 11.4%\n",
      "  religious: Train 8.9% | Val 9.4% | Test 8.0%\n",
      "  threat: Train 8.7% | Val 8.9% | Test 9.2%\n",
      "  troll: Train 10.3% | Val 9.1% | Test 11.0%\n",
      "  Insult: Train 16.8% | Val 17.2% | Test 17.3%\n"
     ]
    }
   ],
   "source": [
    "# Create stratified splits for multi-label data\n",
    "print(\"Creating train/validation/test splits...\")\n",
    "\n",
    "# For multi-label stratification, we'll use the total number of labels as a proxy\n",
    "# This ensures similar distribution of label density across splits\n",
    "\n",
    "X = df_clean['text_cleaned']\n",
    "y = df_clean[label_columns]\n",
    "\n",
    "# First split: separate test set (15%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.15, \n",
    "    random_state=42,\n",
    "    stratify=df_clean['total_labels']\n",
    ")\n",
    "\n",
    "# Second split: separate train and validation (70% train, 15% val from remaining)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.176,  # 0.15/0.85 ≈ 0.176 to get 15% of original data\n",
    "    random_state=42,\n",
    "    stratify=y_temp.sum(axis=1)  # Use total labels for stratification\n",
    ")\n",
    "\n",
    "print(f\"Dataset splits:\")\n",
    "print(f\"  Training set: {len(X_train):,} samples ({len(X_train)/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"  Validation set: {len(X_val):,} samples ({len(X_val)/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"  Test set: {len(X_test):,} samples ({len(X_test)/len(df_clean)*100:.1f}%)\")\n",
    "\n",
    "# Verify label distribution across splits\n",
    "print(f\"\\nLabel distribution across splits:\")\n",
    "for label in label_columns:\n",
    "    train_pct = (y_train[label].sum() / len(y_train)) * 100\n",
    "    val_pct = (y_val[label].sum() / len(y_val)) * 100\n",
    "    test_pct = (y_test[label].sum() / len(y_test)) * 100\n",
    "    print(f\"  {label}: Train {train_pct:.1f}% | Val {val_pct:.1f}% | Test {test_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746c858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preprocessed data...\n",
      "Saved files:\n",
      "  train_dataset1.csv\n",
      "  val_dataset1.csv\n",
      "  test_dataset1.csv\n",
      "  dataset1_cleaned.csv\n",
      "\n",
      "Preprocessing Summary:\n",
      "  original_samples: 16073\n",
      "  cleaned_samples: 16068\n",
      "  train_samples: 11253\n",
      "  val_samples: 2404\n",
      "  test_samples: 2411\n",
      "  label_columns: ['vulgar', 'hate', 'religious', 'threat', 'troll', 'Insult']\n",
      "  avg_text_length: 79.8660069703759\n",
      "  total_toxic_samples: 8487\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed data for model training\n",
    "print(\"Saving preprocessed data...\")\n",
    "\n",
    "# Create train/val/test dataframes\n",
    "train_df = pd.DataFrame({\n",
    "    'text': X_train,\n",
    "    **{col: y_train[col] for col in label_columns}\n",
    "})\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    'text': X_val,\n",
    "    **{col: y_val[col] for col in label_columns}\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'text': X_test,\n",
    "    **{col: y_test[col] for col in label_columns}\n",
    "})\n",
    "\n",
    "# Save to CSV files\n",
    "train_df.to_csv('../data/train_dataset1.csv', index=False)\n",
    "val_df.to_csv('../data/val_dataset1.csv', index=False)\n",
    "test_df.to_csv('../data/test_dataset1.csv', index=False)\n",
    "\n",
    "# Save the complete cleaned dataset\n",
    "df_clean[['text_cleaned'] + label_columns].to_csv('../data/dataset1_cleaned.csv', index=False)\n",
    "\n",
    "print(\"Saved files:\")\n",
    "print(\"  train_dataset1.csv\")\n",
    "print(\"  val_dataset1.csv\") \n",
    "print(\"  test_dataset1.csv\")\n",
    "print(\"  dataset1_cleaned.csv\")\n",
    "\n",
    "# Summary statistics\n",
    "summary_stats = {\n",
    "    'original_samples': len(df),\n",
    "    'cleaned_samples': len(df_clean),\n",
    "    'train_samples': len(train_df),\n",
    "    'val_samples': len(val_df),\n",
    "    'test_samples': len(test_df),\n",
    "    'label_columns': label_columns,\n",
    "    'avg_text_length': df_clean['cleaned_length'].mean(),\n",
    "    'total_toxic_samples': (df_clean['total_labels'] > 0).sum()\n",
    "}\n",
    "\n",
    "print(f\"\\nPreprocessing Summary:\")\n",
    "for key, value in summary_stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
